{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG9KvKMHWFu4"
   },
   "source": [
    "## Ambulance Allocation Through Reinforcement Learning\n",
    "Francisco Aristi\n",
    "\n",
    "Boyan Alipiev \n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVB4ZvWUxD6A"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Reinforcement learning is often perceived as one of the fundamental blocks of Artificial Intelligence. In the majority of its implementations, it focuses on model-less environments, where an agent ‘learns’ based on his/her actions, the states in which these actions were taken, and the respective reward or punishment the agent receives as a consequence of its decisions. After a finite number of iterations, the agent optimises his/her action given the state that he/she is in in order to maximise its payoff or equivalently, minimise its penalties. \n",
    "\n",
    "An emerging problem analysis in Reinforcement Learning is the case when you have two or more different learning agents with different objective functions, where an agent aims to influence the behavior via a mechanism. Literature in this area ranges from Mechanism Design in Game Theory to multi-agent system with learning behavior and a coordination mechanism.[5][8]\n",
    "\n",
    "This paper analyses the coordination problem in an Ambulance System. The patients arrive randomly across regions, and the rate of arrival is unknown. Furthermore, there is a Central Planner that wants to influence the behavior of independent ambulances so that the number of attended patients is maximised. The problem the Central Planner faces is that ambulances optimise other objective function, namely the expected waiting time between patients. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Abstract\n",
    "\n",
    "The report is divided in three different settings with three Reinforcement Learning approaches:\n",
    "\n",
    "- The first approach considers a Central Planner that has full control of ambulances: the central planner learns and plans how to allocate ambulances in regions to achieve the system's objective. This is a single agent reinforcement learning problem.\n",
    "\n",
    "- The second approach involves a multiagent system where there is not a Central Planner and ambulances learn independently by themselves. The ambulances are trying to minimise the expected waiting time between attended patients. \n",
    "\n",
    "- Lastly, we define a model based on Wu's Markov Persuasive Process to describe a mechanism on how the Central Planner can influence the decision of the independent ambulances taking advantage of their asymmetric information over the rate of patients in each region.[12]\n",
    "\n",
    "Surprisingly, the first setting produces similar results to the second setting. The third setting is presented on a theoretical level given the additional computational complications that are introduced in our model. The report further suggests other applications of the third setting.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUmYpT5SKY6G"
   },
   "source": [
    "# Problem Description\n",
    "\n",
    "There are $n$ ambulances in a city and $m$ regions. At each step $t$ a patient arrives to a region $j \\in [m]$  drawn from a probability distribution. The probability distribution over regions $P([m]) \\in \\{(p_1, p_2, ..., p_m)|  \\sum_{i=1}^m p_i = 1\\}$ (to simplify the problem we assume this probability distribution is always the same). \n",
    "\n",
    "Ambulances are located within regions and they can attend a patient, if it coincides that a patient arrives at their location $j$. If there are more than 1 ambulances in the region the ambulance that attends the patient is drawn from random uniform distribution.  More importantly, if there is not ambulance in the region the patient dies. \n",
    "When an ambulance attends a patient it moves the patient to another region randomly.\n",
    "\n",
    "The day ends at a time $T$ and from $[1,T]$ ambulances can move from one region to the other freely. \n",
    "\n",
    "The system problem is the following: given that the distribution of arrival of patients is unknown to the ambulances, what is the best learning algorithm to find an arrangement of ambulances that minimise unattended patients in expectation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru-dKC9Fyl2B"
   },
   "source": [
    "# Motivation and Objective\n",
    "\n",
    "Mexico City Ambulance System consists of a central regualtor and independent ambulances. The former has full control of the police force, city cameras, and indirect influence over ambulances via radio communication to disclose information about new patients.\n",
    "\n",
    "A problem the First Respondent system has faced is how to allocate ambulances strategically to minimise non attended patients, subject to obedient behavior from the ambulances. Even though signficant efforts have been made to implement the policy (mainly by establishing private communication from an ambulance to the central planer), a study in 2018 revealed that each day from an average of 1000 ambulances, only 30% were attended. \n",
    "Additionally, the average response time to carry a patient to a hospital is 42 minutes, which is unreliable for critical cases (strokes, EVC etc.) [10].\n",
    "\n",
    "An analysis developed by Aristi in 2019 showed that the problem was due to different incentives between the central planer and the independent ambulances.[1] The first ones' objective is to minimise unattended patients with good quality response time, while the latter ones aim to minimise the time waiting between patients. These differences generated an environment where most ambulances are concentrated in the densest areas of the city competing for the same patient, while other city areas are left unattended. \n",
    "Faced with uncertainty in the decision making process of each actor, the system is hindered even further.\n",
    "\n",
    "The objective in this work is to understand how would the metric of non-attended patients improve if the cental planer had full control of ambulances,given that a Reinforcement Learning Algorithm established how to allocate them versus the case where each ambulance is independent and learns by itself. \n",
    "More importantly, we aim to arrive to a mechanism that can implement a system where the central planner persuades ambulances to behave in a way that improves the non-attended metric.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg-vltREW2Ty"
   },
   "source": [
    "# Central Planner with Full Control Environment\n",
    "\n",
    "Suppose there is a central planner that has full control over the ambulances, i.e. he can allocate ambulances at his will and they will obey to do it. \n",
    "\n",
    "With full information this situation can be represented as a Markov Decision Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0ab4oZSKnVJ"
   },
   "source": [
    "## Markov Decision Process Model of the Ambulance Allocation Problem\n",
    "\n",
    "We assume the system transitions in the following order:\n",
    "1. State $S_t$ is observed.\n",
    "2. Ambulances are allocated in a new way through taking action $A_t$\n",
    "3. A patient arrives to a region $j$ \\\\\n",
    "    3.1. Rewards are given. \\\\\n",
    "    3.2. The ambulance takes the patient randomly to another region $j´$ drawn with a distribution with equal probability over regions. \\\\\n",
    "    3.3. The new state $S_{t+1}$ is realised. \\\\\n",
    "  ... \\\\\n",
    "\n",
    "(The system continues until step $T$)\n",
    "\n",
    "\n",
    "Formally we define a Markov Decision Process model as follows. \n",
    "\n",
    "- State space $S$ for the central planer $S = \\{(s_1,...,s_m)| \\sum_{i=1}^m s_i = n\\}$ where $s \\in S$\n",
    "- Action space of the environment are any to move an ambulance **Left**, **Right**, or **Stay**, thus $A \\subset S$.\n",
    "- The transition probability from $S_t,A_t$ to $S_{t+1}$ is defined by the ocurrence of a patient in a region $j$ and, if there is an ambulance in the region $j$, the place where the ambulance will be taken $j'$. \n",
    "- Rewards $R$ are either -1 if there is a patient at $j$ and $s_j=0$, and 0 other wise.\n",
    "\n",
    "Finally, notice this MDP model satisfies *Markovianity* and *time-homogeneity* which is important to obtain the Optimal Solution.\n",
    "\n",
    "## Uncertainty of Patient Arrival\n",
    "\n",
    "In real life it is impossible to know with certainty where the next patient will occur, and respectively where the ambulance would be taken. Therefore, the transition probability is unkown for any agent of the system. \n",
    "\n",
    "In the following sections we analyse how to solve the Learning and Planning problem of the ambulance allocation in a city.\n",
    "\n",
    "## Central Planner Policy, Return and Value\n",
    "\n",
    "The Central Planer Policy is deterministic, markov and homogeneous for any $t$, i.e. $\\pi_t(a,s_t) = 1 \\text{ for some } a \\text{ and zero for the other actions }$.\n",
    "\n",
    "The central planer's objective is to avoid unattended patients. Therefore, it aims to determine a policy for every t that maximises: $$E^\\pi[G_t ]$$ where the return is defined as $G_t = \\sum_{i=0}^T \\gamma^{i}R_i $.\n",
    "\n",
    "As seen in previous literature, the value is the expected return staring from s and is defined $$V^\\pi(s) = E^\\pi[G_t| S_t=s]$$\n",
    "\n",
    "## Solution\n",
    "\n",
    "For the solution we implement a tabular Q-learning algorithm that performs the learning and planning activities.\n",
    "\n",
    "The method is model-free since it doesn't assume a structure of the underlying stochastic process, and off policy as the behavior policy ($\\epsilon - Greedy$) is independent of the target policy.\n",
    "\n",
    "As described in lectures:\n",
    "$$Q^{opt}(s,a) = E[R_t + \\gamma \\ max_{a'} Q^{opt}(S_{t+1},a')|A_t = a, S_t =s )$$ \n",
    "\n",
    "\n",
    "## Q-Learning: Pseudocode\n",
    "- *Initialisation*: arbitrary Q.\n",
    "- **Repeat** for each episode:\n",
    "  **Initialise** state s\n",
    "  \n",
    "  **Repeat** for each step of the episode: \\\\\n",
    "    a ← action s using policy derived from ϵ-Greedy\\\\\n",
    "    Take action a, observe reward r and next state s' \\\\\n",
    "   $ Q(s,a) \\leftarrow Q(s,a)+\\alpha[r+ \\gamma \\ max_{a'} Q^{opt}(S_{t+1},a')]$ \\\\\n",
    "    $s \\leftarrow s'$ \\\\\n",
    "  **until** s is a terminal state.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtojtC1Jv6Ac"
   },
   "source": [
    "## Example: Central Planner with One Ambulance\n",
    "\n",
    "In the following section we develop an example instantiated in a three region environment with one ambulance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LA70irP-YkZ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class City:\n",
    "  \"\"\"\n",
    "    City environment. It simulates where agents arrive and  where ambulances are taken after\n",
    "    a patient is attended.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, ambulances, regions, T, p):\n",
    "    self.n = ambulances\n",
    "    self.m = regions\n",
    "    self.initial_state = np.zeros(regions)\n",
    "    self.reward = None\n",
    "    self.state = [0]*self.m\n",
    "    self.is_terminal = None\n",
    "    self.T = T\n",
    "    self.time_counter = None\n",
    "    self.distribution = p\n",
    "\n",
    "\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    self.reward = 0.0\n",
    "    self.is_terminal = False\n",
    "    self.time_counter = 0 \n",
    "    self.state = [0,1,0]     \n",
    "    return self.state  \n",
    "\n",
    "  def patient_arrival(self):\n",
    "    return np.random.choice(range(0,self.m),p = self.distribution)\n",
    "\n",
    "  def step(self, action):\n",
    "    \"\"\"\n",
    "      One step decision from the central planner:\n",
    "      action: m tuple with the position of ambulances, \n",
    "      constrained on n, over the sum of ambulances in all the regions.\n",
    "    \"\"\"\n",
    "\n",
    "    new_state = [0]*3\n",
    "    m_incident = self.patient_arrival()\n",
    "    #print(m_incident)\n",
    "    if action[m_incident] != 0:\n",
    "      movement = np.random.randint(0,self.m)\n",
    "\n",
    "      new_state[movement] = new_state[movement] + 1   \n",
    "      self.reward = 0\n",
    "      self.state = new_state\n",
    "    else:\n",
    "      self.reward = -1 \n",
    "      self.state = action\n",
    "\n",
    "    self.time_counter += 1 \n",
    "\n",
    "    if self.time_counter == self.T:\n",
    "      self.is_terminal = True     \n",
    "\n",
    "    return self.state, self.reward, self.is_terminal\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE0Xemk0kuQn"
   },
   "outputs": [],
   "source": [
    "stay = 0\n",
    "left = 1\n",
    "right = 2\n",
    "\n",
    "actions = [stay, left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zO5hAMeymDWn"
   },
   "outputs": [],
   "source": [
    "def eps_greedy_policy(qsa, epsilon=0.01):\n",
    "  '''\n",
    "  qsa : tabular information about the state-action function\n",
    "  epsilon: probability of exploring.\n",
    "  '''\n",
    "  if np.random.binomial(1, epsilon) == 1:\n",
    "      return np.random.choice(actions)\n",
    "  else:\n",
    "      return np.random.choice([action_ for action_, value_ in enumerate(qsa) if value_ == np.max(qsa)])\n",
    "\n",
    "\n",
    "def q_learning(qsa, next_qs, r, alpha=0.1, gamma=.3):\n",
    "  \"\"\"\n",
    "    Main Q-Learning method\n",
    "    qsa: actual state- action value\n",
    "    next_qs: vector of values indexed by actions.\n",
    "    r:reward\n",
    "  \"\"\"  \n",
    "  return qsa + alpha * (r + gamma * np.max(next_qs) - qsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2jOpd78ELQ2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_q_qlearning(m , n = 1):\n",
    "  '''\n",
    "  Method that instantiates the data structure for tabular information.\n",
    "  Each state has a key and is linked to a vector of |A| dimensions.\n",
    "  '''\n",
    "\n",
    "  q_qlearning = dict()\n",
    "  for j in range(0,m):\n",
    "    state = [0]*m\n",
    "    state[j] = 1\n",
    "    q_qlearning[str(state)] = [0]*3\n",
    "  \n",
    "  return q_qlearning\n",
    "\n",
    "\n",
    "def change(state,action):\n",
    "  \"\"\"\n",
    "  Method that helps the process of updating the State based on the action decision.\n",
    "  \"\"\"\n",
    "\n",
    "  new_state = [0]*3\n",
    "\n",
    "  if action == 0:\n",
    "    return state\n",
    "  elif action == 1:\n",
    "    for i in range(len(state)):\n",
    "      if i != 0 and 1 == state[i]:\n",
    "        new_state[i-1] = 1 \n",
    "        break \n",
    "      elif i == 0 and 1 == state[i]:\n",
    "        new_state[0] = 1  \n",
    "        break    \n",
    "                       \n",
    "  elif action == 2:\n",
    "    for i in range(len(state)):\n",
    "      if i != 2 and 1 == state[i]:\n",
    "        new_state[i+1] = 1\n",
    "        break\n",
    "      elif i == 2 and 1 == state[i]:\n",
    "        new_state[2] = 1  \n",
    "        break \n",
    "\n",
    "  return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eGV1xoWk3Hd",
    "outputId": "8a32706c-9171-4915-f95d-c9ea74e6c944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "episodes = 30\n",
    "runs = 20\n",
    "\n",
    "rewards_qlearning = np.zeros(episodes)\n",
    "rewards_random = np.zeros(episodes)\n",
    "\n",
    "p = [.2,.6,.2]\n",
    "\n",
    "env_q_learning = City(1, 3, 100, p)\n",
    "env_random = City(1, 3, 100, p)\n",
    "\n",
    "\n",
    "\n",
    "for r in range(runs):\n",
    "    print(r)\n",
    "\n",
    "    q_qlearning = create_q_qlearning(env_q_learning.m)\n",
    "    q_random = create_q_qlearning(env_random.m)\n",
    "\n",
    "    for i in range(episodes):\n",
    "\n",
    "        state_q = env_q_learning.reset()\n",
    "        state_random = env_random.reset()\n",
    "\n",
    "        done_q = False\n",
    "        done_random = False\n",
    "\n",
    "        g_q = 0.0\n",
    "        g_random = 0.0       \n",
    "  \n",
    "            \n",
    "        #Q-Learning\n",
    "        while not done_q:\n",
    "            \n",
    "            a_q = eps_greedy_policy(q_qlearning[str(state_q)])\n",
    "\n",
    "\n",
    "            change_state = change(state_q,a_q)\n",
    "\n",
    "\n",
    "            #print((state_q, change_state, a_q))\n",
    "            next_state_q, r_q, done_q = env_q_learning.step(change_state)\n",
    "\n",
    "            #print((state_q, change_state, next_state_q, r_q, done_q, a_q))\n",
    "            g_q += r_q\n",
    "            # Q-learning updates, note the second argument\n",
    "            q_qlearning[str(state_q)][a_q] = q_learning(q_qlearning[str(state_q)][a_q],\n",
    "                                                        q_qlearning[str(next_state_q)], r_q)\n",
    "            #print(q_qlearning)\n",
    "            state_q= next_state_q\n",
    "            \n",
    "        #Q-Learning\n",
    "        while not done_random:\n",
    "            \n",
    "            a_r = np.random.choice(actions)\n",
    "\n",
    "            change_state_random = change(state_random,a_r)\n",
    "\n",
    "\n",
    "            #print((state_q, change_state, a_q))\n",
    "            next_state_random, r_random, done_random = env_random.step(change_state_random)\n",
    "            g_random += r_random\n",
    "\n",
    "            state_random= next_state_random\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        rewards_qlearning[i] += g_q\n",
    "        rewards_random[i] += g_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyONU_N5Sh0F",
    "outputId": "83dc6f75-11dc-408a-9848-f773aedb4638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1321., -1318., -1340., -1348., -1357., -1330., -1340., -1294.,\n",
       "       -1309., -1351., -1369., -1303., -1368., -1316., -1320., -1341.,\n",
       "       -1358., -1327., -1331., -1304., -1346., -1294., -1326., -1318.,\n",
       "       -1337., -1356., -1378., -1356., -1325., -1363.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fv3vnrlNYSj0",
    "outputId": "32e1937b-4336-4ffc-a6f2-a68a6d973bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-64.85, -66.25, -66.4 , -65.45, -65.75, -65.45, -67.25, -65.85,\n",
       "       -65.7 , -66.  , -68.4 , -65.55, -68.55, -66.85, -65.95, -67.3 ,\n",
       "       -65.55, -67.95, -67.8 , -67.3 , -65.55, -65.  , -67.55, -66.45,\n",
       "       -68.1 , -67.75, -69.2 , -65.25, -66.25, -64.45])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_qlearning /= runs\n",
    "rewards_qlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPnXe2iDUtM-",
    "outputId": "e6201286-44e5-41d1-f34c-ce2676071c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-67.9 , -66.9 , -68.45, -63.9 , -66.85, -67.7 , -65.5 , -66.95,\n",
       "       -67.3 , -66.05, -65.75, -64.25, -65.9 , -66.65, -67.25, -67.  ,\n",
       "       -66.4 , -66.05, -66.7 , -66.45, -66.6 , -65.2 , -65.8 , -65.15,\n",
       "       -66.15, -68.85, -68.25, -67.15, -67.6 , -64.7 ])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_qlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "d34azCf1Ye7u",
    "outputId": "0589f191-5d5d-4760-c02f-2bdac8dd649d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_rewards(plots):\n",
    "    plt.figure()\n",
    "    for plot in plots:\n",
    "        method, method_title = plot\n",
    "        plt.plot(method, label=method_title)\n",
    "    # plt.plot(r_qlearning, label='Q-learning')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Sum of rewards during episodes')\n",
    "    plt.ylim([-100, 0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "rewards_random /= runs\n",
    "rewards_qlearning /= runs\n",
    "\n",
    "plot_rewards([[rewards_random, 'Random'], [rewards_qlearning, 'Q-learning']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nujkKPUxOmhE"
   },
   "source": [
    " \n",
    "## Observations and Conclusions\n",
    "\n",
    "The implemented setting involved n=1, m=3 and a probability distibution of (.2, .6, .2) for the arrival of patients in a region. It was noted in the study that a more homogeneous distribution impeded learning for the Q-Learning algorithm. At the end, the selected characterisation was one that involved a region with a probability of more than 50%. This assumption is realistic because the rate of patients is considerably higher in the densest regions, which in places like Mexico City, are in the central neighbourhoods.\n",
    "\n",
    "\n",
    "Moreover, the discount factor,Gamma($\\gamma$), has to be lower to achieve a greater learning and better performance.Epsilon($\\epsilon$) has to be lower because there aren't too many things to explore.\n",
    "\n",
    "\n",
    "A problem with this setting is the increasing exponential rate in the action and state space size for each ambulance that is introduced in the system. In a big n this affects the estimation of state-value function and makes it impossible to converge to a solution.\n",
    "\n",
    "Additionally, in many Emergency Systems,e.g. Mexico City, ambulances are part of the system, but they are independent from the authority and they act on their own will under the law. This is an important fact to consider and that would be analysed in the next multiagent section.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Approximation\n",
    "\n",
    "Given that the state and action space that we examine are relatively small compared to the problem at hand in the real world, we briefly mention the implemntation of linear approximation of Q-learning. The idea is to approximate the Q-values once the state and action spaces are significanlty larger and thus can impede the straightforward implementation of the Q-learning algorithm due to the added complexity. A specific concept for the Linear Approximation in our problem is that the coefficients in certain cases need to be kept constant at 0:thus some cases shouldn't add influence to the overall estimation. The state-action pairs that need to be excluded are two: given that the state of a particulat ambulance is the left-most position,$s$[1] or $s$[0], depending on the notation, the ambulance isn't able to make a Left move, thus $a$[1] or $a$[0],again depending on the choice of notation. The other case is when the state-action pair define the rightmost state and $a$[R]. Thus, the linear approximation is going to have 2 less coefficients to be determined. In the case discussed above, the state-action pairs will decrease from 9 to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create an approximate function. We have the following options:\n",
    "1. A function receives a $(s,a)$ and ouputs $Q(s,a,w)$\n",
    "2. A function receives a state (s) and outputs $Q(s,a_1;w),...,Q(s,a_{|A|};w)$ \n",
    "\n",
    "\n",
    "An important note is: the state Action space depend on number of players: $3^n$ \n",
    "\n",
    "## Fitted Q Iteration algorithm\n",
    "- initialize $\\hat Q$, $\\bar{Q}$, k = 0.\n",
    "- While (k < K) Repeat: \n",
    "    - Generate enought data $\\{(S_t,A_t,R_t,S_{t+1}) \\}_{t=1}^T$ using policy derived from $\\hat Q $ with epsilon-greedy.\n",
    "    - Compute $\\hat{Q}$ as the argmin of:\n",
    "        $\\hat{Q} = argmin_w \\sum_{t=1}^T[R_t+max_a \\bar{Q}(S_{t+1},a)-Q(S_t,A_t;w)]$\n",
    "    - $\\bar{Q} = \\hat{Q}$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"q_approximation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 9)                 54        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf \n",
    "from keras import layers\n",
    "\n",
    "n = 2\n",
    "m = 5\n",
    "\n",
    "approximation = keras.Sequential(name='q_approximation')\n",
    "approximation.add(layers.Input(m))\n",
    "approximation.add(layers.Dense(9,activation='relu'))\n",
    "approximation.add(layers.Dense((9)))\n",
    "approximation.summary()\n",
    "\n",
    "approximation.compile(\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.1),\n",
    "    loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class City:\n",
    "  \"\"\"\n",
    "    City environment. It simulates where agents arrive and  where ambulances are taken after\n",
    "    a patient is attended.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, ambulances, regions, T, p):\n",
    "    self.n = ambulances\n",
    "    self.ambulances = [0]*self.m\n",
    "    self.m = regions\n",
    "    self.reward = None\n",
    "    self.state = [0]*self.m\n",
    "    self.is_terminal = None\n",
    "    self.T = T\n",
    "    self.time_counter = None\n",
    "    self.distribution = p\n",
    "\n",
    "\n",
    "  def reset(self):\n",
    "\n",
    "    self.reward = 0.0\n",
    "    self.is_terminal = False\n",
    "    self.time_counter = 0 \n",
    "    \n",
    "    for ambulance in range(0, self.n):\n",
    "        position = np.random.choice(range(0,self.m))\n",
    "        \n",
    "        self.ambulances[ambulance] = position\n",
    "        \n",
    "        self.state[m] += 1\n",
    "        \n",
    "    return self.state  \n",
    "\n",
    "  def patient_arrival(self):\n",
    "    return np.random.choice(range(0,self.m),p = self.distribution)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def step(self, actions: str)-> (list, int, bool):\n",
    "    \"\"\"\n",
    "      One step decision from the central planner:\n",
    "      actions: n string with the decision of ambulances, e.g 102, 012, 021 etc. \n",
    "    \"\"\"\n",
    "\n",
    "    def action2state(action):\n",
    "        for ambulance in range(0, self.n):\n",
    "            new_state = [0]*self.m\n",
    "            action = actions[ambulance]\n",
    "\n",
    "            if action == 1:\n",
    "                self.ambulances[ambulance] = (self.ambulances[ambulance]-1)%self.m\n",
    "            elif (action == 1)\n",
    "                self.ambulances[ambulance] = (self.ambulances[ambulance]+1)%self.m \n",
    "                \n",
    "            new_state[ self.ambulances[ambulance] ] += 1 \n",
    "    \n",
    "    return new_state\n",
    "\n",
    "    self.state = action2state(action)\n",
    "    \n",
    "    \n",
    "    m_incident = self.patient_arrival()\n",
    "    #print(m_incident)\n",
    "    if self.state[m_incident] != 0:\n",
    "      movement = np.random.randint(0,self.m)\n",
    "\n",
    "      self.state[movement] = self.state[movement] + 1   \n",
    "      self.state[m_incident] = self.state[m_incident] - 1\n",
    "      self.reward = 0\n",
    "        \n",
    "    else:\n",
    "      self.reward = -1 \n",
    "\n",
    "    self.time_counter += 1 \n",
    "\n",
    "    if self.time_counter == self.T:\n",
    "      self.is_terminal = True     \n",
    "\n",
    "    return self.state, self.reward, self.is_terminal\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(ambu, n):\n",
    "    s = ''\n",
    "    \n",
    "    if n < 3:\n",
    "        n = str(n)\n",
    "        for _ in range(0,ambu-len(n)):\n",
    "            n = \"0\"+n\n",
    "        return str(n)\n",
    "\n",
    "    while n != 0:\n",
    "        s = str(n%3) + s\n",
    "        n = n//3\n",
    "        \n",
    "    for _ in range(0,ambu-len(s)):\n",
    "        s = \"0\"+s\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1011102200212000122202010121110011222012000121002011012221120122101010001001100102220120020001101102'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base(100,200000000000000000000000000000000000000000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "episodes = 30\n",
    "runs = 20\n",
    "\n",
    "rewards_qlearning = np.zeros(episodes)\n",
    "rewards_random = np.zeros(episodes)\n",
    "\n",
    "p = [.2,.6,.2]\n",
    "\n",
    "env_fitted_q_learning = City(n, m, 100, p)\n",
    "env_random = City(n, m, 100, p)\n",
    "\n",
    "\n",
    "\n",
    "for r in range(runs):\n",
    "    print(r)\n",
    "\n",
    "    # // Borrar esto\n",
    "    q_qlearning = create_q_qlearning(env_q_learning.m)\n",
    "    q_random = create_q_qlearning(env_random.m)\n",
    "\n",
    "    for i in range(episodes):\n",
    "\n",
    "        \n",
    "        state_q = env_q_learning.reset()\n",
    "        state_random = env_random.reset()\n",
    "\n",
    "        done_q = False\n",
    "        done_random = False\n",
    "\n",
    "        g_q = 0.0\n",
    "        g_random = 0.0       \n",
    "  \n",
    "            \n",
    "        #Q-Learning\n",
    "        while not done_q:\n",
    "            \n",
    "            # // Cambiar a fitted\n",
    "            a_q = eps_greedy_policy(q_qlearning[str(state_q)])\n",
    "\n",
    "\n",
    "            #print((state_q, change_state, a_q))\n",
    "            next_state_q, r_q, done_q = env_fitted_q_learning.step(a_q)\n",
    "\n",
    "            #print((state_q, change_state, next_state_q, r_q, done_q, a_q))\n",
    "            g_q += r_q\n",
    "\n",
    "        # // Make algorithm learn\n",
    "        \n",
    "        \n",
    "        # // Change of target.\n",
    "        \n",
    "        \n",
    "        #Q-Learning\n",
    "        while not done_random:\n",
    "            \n",
    "            a_r = np.random.choice(actions)\n",
    "\n",
    "            change_state_random = change(state_random,a_r)\n",
    "\n",
    "\n",
    "            #print((state_q, change_state, a_q))\n",
    "            next_state_random, r_random, done_random = env_random.step(change_state_random)\n",
    "            g_random += r_random\n",
    "\n",
    "            state_random= next_state_random\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        rewards_qlearning[i] += g_q\n",
    "        rewards_random[i] += g_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7hkY0cBt4ob"
   },
   "source": [
    "# Independent Ambulances without a Central Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhgec7rxuGqK"
   },
   "source": [
    "Mexico City and many cities do not have a centralised system. In fact, the case is often the opposite: ambulances belong to independent companies and they attend patients based on their own objectives, information, and values. \n",
    "\n",
    "In this section we analyse what is the result of these circumstances in the emergency system. To attain insight we model the Emergency System as a Multi-Agent Reinforcement Learning, where all ambulances are competing among themselves to attend patients as soon as possible. In particular the framework that will be used is Markov Stochastic Games. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZuTgfkK4vfC"
   },
   "source": [
    "## Markov Stochastic Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hizZIoUo4yS2"
   },
   "source": [
    "**General Setting**\n",
    "\n",
    "We solve a Markov Stochastic Game as described in (Zhang, Kaiqing, et al, 2021) to model the problem of many ambulances in a city making decisions. \n",
    "The Markov Stochastic Game is a competitive game between the agents and it is defined in the following way:\n",
    "- $[n]$ ambulances are in the system.\n",
    "- The state space for an ambulance $S^{i}$ is the location of ambulances in the city. Thus, ambulances can see where all the other units are located.\n",
    "- The action space for ambulance $i$ is define as $A^{i} = \\{L,R,Stay\\}$. Where $A = A^1 \\times ...  \\times A^n$ is the joint action space.\n",
    "- The transition probability corresponds to a mapping $P: S \\times A \\rightarrow \\triangle(S)$. As before it is stochastic where a patient will exist and the location to which the patient will be taken by the ambulance.\n",
    "- The rewards is -1 for each step they haven't attended a patient and (n-1) in each case they have attended a patient. \n",
    "\n",
    "Each ambulance tries to minimise its expected waiting time between patients they attended, or alternatively maximise the number of patients it attends. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAJrglOX4bwJ"
   },
   "source": [
    "## Analysis of the Stochastic Game\n",
    "\n",
    "**Nash equilibria**\n",
    "Usually, an interest in literature is to analyse the convergence of the system to a Nash Equilibrium. \n",
    "\n",
    "**Definition. Nash Equilibrium** A Nash Equilibrium in a Markov Game is a joint policy $\\pi^* = (\\pi^{*1}, ..., \\pi^{*N})$. Such that for any $s \\in S$ and $i \\in N$.\n",
    "\n",
    "$$V^i_{{\\pi^*i},{\\pi^*-i}} \\geq V^i_{{\\pi^i},{\\pi^*-i}} \\text{for any } \\pi^{i}$$\n",
    "\n",
    "Nevertheless, looking for Nash Equilibria in Stochastic Games assumes the rationality of the agents while playing with other agents, which in our system means they know where the other agents are and rationality in the way in their decision-making. \n",
    "\n",
    "Additionally, it has been noted that it is very expensive to analyse Markov Stochastic Games that try to reach a Nash Equilibrium. Even the simplest case, a three player game in a bimatrix equilibria is PPAD-complete (Daskalakis, 2006). Recent literature points out that even Coarse Correlated Equilibria in Multi Agent Systems is NP-hard.[3]\n",
    "\n",
    "In our problem analysis we don't seek to achieve a Nash Equilibria. Our problem focuses on analysing the effect of the decisions, caused by the learning agents given the information they have. \n",
    "\n",
    "**Possible Non - Convergence in Stochastic Games**\n",
    "A problem with Markov Stochastic games is the possible non-stationarity of the system, due to the dependency of each agent for the transition of states and outcome of the system.\n",
    "\n",
    "Theoretically if an agent ignores non-stationary environment with an independent learning strategy, it is not guaranteed that the result will converge.[2]\n",
    "\n",
    "Nevertheless, as mentioned in (Ming, 1993) and (Laetitia et al. 2012)  single-agent independent learning achieves satisfactory results in practice.[12][7]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTIUbyic04w9"
   },
   "source": [
    "**Single-Agent Learner Assumption**\n",
    "\n",
    "To avoid the problem of non-stationarity, we assume the ambulances are single agent learners. In particular, at the beginning of each step a queue of ambulances is drawn from a random distribution and each ambulance chooses its best response dynamic by using Q-learning method and the private information about the environment. \n",
    "\n",
    "An implication of the assumption is that the agents treat the other ambulances as if they were part of the environment, which allows the model to be treated as Markovian.[2]\n",
    "There is a price to pay in this assumption: either the assumption would be realised and the agents would converge to a Nash Equilibrium or it will not converge (Jaakkola et al., 1994).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwST_3gy32SU"
   },
   "source": [
    "## Single-Agent Q-Learning: Pseudocode\n",
    "- **Initialisation**: arbitrary Q.\n",
    "- **Repeat** for each episode:\n",
    "- **Initialise** state s\n",
    "- **Repeat** for each step of the episode: \\\\\n",
    "  - Generate random queue of ambulances.\n",
    "  - **Repeat** for each ambulance: \\\\\n",
    "    - a ← action s using policy derived from ϵ-Greedy\\\\\n",
    "    - Take action \\\\\n",
    "  - Observe reward r and next state s'\n",
    "  - **Repeat** for each ambulance \\\\\n",
    "    - $Q(s,a) \\leftarrow Q(s,a)+\\alpha[r+ \\gamma \\ max_{a'} Q^{opt}(S_{t+1},a')]$ \\\\\n",
    "    - $s \\leftarrow s'$ \\\\\n",
    "  - **Stop Until** s is a terminal state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZjZ6ovi7kWD"
   },
   "outputs": [],
   "source": [
    "class City_multiagent(City):\n",
    "    def __init__(self, ambulances, regions, T, p):\n",
    "        super().__init__( ambulances, regions, T, p)\n",
    "        self.ambulances = list()\n",
    "        self.time_counter = 0\n",
    "\n",
    "    def reset(self):\n",
    "      self.reward = 0.0\n",
    "      self.is_terminal = False\n",
    "      self.time_counter = 0      \n",
    "      return self.state \n",
    "        \n",
    "\n",
    "    def create_ambulances(self):\n",
    "      \n",
    "      new_state = [0]*self.m\n",
    "      for i in range(self.n):\n",
    "\n",
    "        random = np.random.randint(0,self.m)\n",
    "        self.ambulances.append(Ambulance(i, random, self.m))\n",
    "        new_state[random] = new_state[random] + 1\n",
    "\n",
    "      \n",
    "      self.state = new_state\n",
    "\n",
    "    def step(self, action):\n",
    "      \"\"\"\n",
    "        One step decision from the central planner:\n",
    "        action: m tuple with the position of ambulances, \n",
    "        constrained on n, over the sum of ambulances in all the regions.\n",
    "      \"\"\"\n",
    "\n",
    "      new_state = list(action)\n",
    "      m_incident = self.patient_arrival()\n",
    "\n",
    "\n",
    "      #print(m_incident)\n",
    "      if action[m_incident] != 0:\n",
    "        #print(f\"inci {action[m_incident]}\")\n",
    "        ambulance_rank = np.random.randint(0,action[m_incident])  \n",
    "        movement = np.random.randint(0,self.m)\n",
    "\n",
    "        new_state[m_incident] = new_state[m_incident] - 1\n",
    "        new_state[movement] = new_state[movement] + 1   \n",
    "        self.reward = 0\n",
    "        self.state = new_state\n",
    "\n",
    "        \n",
    "      else:\n",
    "        ambulance_rank = -1\n",
    "        movement = -1\n",
    "        self.reward = -1 \n",
    "        self.state = action\n",
    "       \n",
    "\n",
    "      self.time_counter += 1 \n",
    "\n",
    "      if self.time_counter == self.T:\n",
    "        self.is_terminal = True     \n",
    "\n",
    "\n",
    "      return self.state, self.reward, self.is_terminal, m_incident, movement, ambulance_rank\n",
    "\n",
    "    def transition_state(self):\n",
    "      transition_state = [0]*self.m\n",
    "      for ambulance in self.ambulances:\n",
    "        #print(ambulance.position)\n",
    "        transition_state[ambulance.position] += 1\n",
    "\n",
    "      return transition_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-yJcr7RpIp5"
   },
   "outputs": [],
   "source": [
    "class Ambulance:\n",
    "  def __init__(self, number, position, regions):\n",
    "    self.position = position\n",
    "    self.seen_state = None    \n",
    "    self.rewards_qlearning = np.zeros(episodes)\n",
    "    self.g_q = 0.0\n",
    "    self.number = number\n",
    "    self.q_qlearning = dict()\n",
    "    self.a_q = None\n",
    "    self.m = regions\n",
    "    stay = 0\n",
    "    left = 1\n",
    "    right = 2\n",
    "\n",
    "    self.actions = [stay, left, right]\n",
    "\n",
    "\n",
    "\n",
    "  def set_postion(self, action):\n",
    "    #if self.position>0 and self.position<\n",
    "      self.a_q = action\n",
    "      self.position = [self.position,self.position-1,self.position+1][action] \n",
    "\n",
    "  def q_qlearning_(self, state):\n",
    "    \n",
    "    if state not in self.q_qlearning.keys():\n",
    "      print(state)\n",
    "      self.q_qlearning[state] = [0]*3\n",
    "\n",
    "    return self.q_qlearning[state] \n",
    "\n",
    "  def eps_greedy_policy(self, qsa, epsilon=0.01):\n",
    "    \n",
    "    actions = self.actions\n",
    "    if (self.position == 0):\n",
    "      actions = [stay, right]\n",
    "      get_items = itemgetter(0,2)\n",
    "      qsa = get_items(qsa)\n",
    "\n",
    "    elif (self.position == self.m-1):\n",
    "      actions = [stay, left]   \n",
    "      get_items = itemgetter(0,1)\n",
    "      qsa = get_items(qsa)\n",
    "\n",
    "    if np.random.binomial(1, epsilon) == 1:              \n",
    "        return np.random.choice(actions)\n",
    "    else:\n",
    "        a_q = np.random.choice([action_ for action_, value_ in enumerate(qsa) if value_ == np.max(qsa)])\n",
    "        if self.position == 0 and a_q == 1:\n",
    "          a_q = 2\n",
    "    \n",
    "        return a_q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def q_learning(self, qsa, next_qs, r, alpha=0.1, gamma=.3):  \n",
    "      return qsa + alpha * (r + gamma * np.max(next_qs) - qsa)\n",
    "\n",
    "    #print(self.q_qlearning)\n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSwWpL_R8dWO",
    "outputId": "a54c1298-da34-4b21-914b-dc26a2825a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0, 2, 0, 0]\n",
      "[0, 1, 1, 0]\n",
      "[0, 0, 2, 0]\n",
      "[0, 0, 2, 0]\n",
      "[0, 1, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 1, 0, 0]\n",
      "[1, 1, 0, 0]\n",
      "[0, 1, 0, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 1, 0, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 0, 0, 2]\n",
      "[0, 0, 0, 2]\n",
      "[0, 2, 0, 0]\n",
      "[2, 0, 0, 0]\n",
      "[2, 0, 0, 0]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "episodes = 100\n",
    "runs = 10\n",
    "\n",
    "rewards_qlearning_cp = np.zeros(episodes)\n",
    "\n",
    "p = [.2,.6,.2,0]\n",
    "\n",
    "env_q_learning = City_multiagent(2, 4, 100, p)\n",
    "env_q_learning.create_ambulances()\n",
    "\n",
    "\n",
    "for r in range(runs):\n",
    "    print(r)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(episodes):\n",
    "\n",
    "        state_q = env_q_learning.reset()\n",
    "\n",
    "        done_q = False\n",
    "        g_q_cp = 0.0\n",
    "            \n",
    "        #Q-Learning\n",
    "        while not done_q:\n",
    "\n",
    "\n",
    "          random.shuffle(env_q_learning.ambulances)\n",
    "\n",
    "          \n",
    "          for ambulance in env_q_learning.ambulances:\n",
    "            #For each ambulance\n",
    "\n",
    "              #print(f\"State: {str(state_q)}\")\n",
    "              ambulance.seen_state = state_q\n",
    "              a_q = ambulance.eps_greedy_policy(ambulance.q_qlearning_(str(state_q)))\n",
    "              #print(ambulance.q_qlearning)\n",
    "              #print(f\"Action: {a_q}\")\n",
    "              ambulance.set_postion(a_q)\n",
    "\n",
    "              change_state = env_q_learning.transition_state()\n",
    "\n",
    "              state_q = change_state\n",
    "\n",
    "          # All ambulances changed the state\n",
    "          #print((state_q, change_state, a_q))\n",
    "          next_state_q, r_q, done_q, m_incident, movement, chosen_ambulance = env_q_learning.step(change_state)\n",
    "          #print(( change_state, next_state_q, r_q, m_incident, movement, done_q, a_q, chosen_ambulance))\n",
    "          g_q_cp += r_q\n",
    "          counter = 0\n",
    "          for ambulance in env_q_learning.ambulances:\n",
    "\n",
    "\n",
    "              #Fix this. \n",
    "\n",
    "              if ambulance.position == m_incident:\n",
    "                #print(f\"position: {ambulance.position}\")\n",
    "                #print(f\"counter: {counter}, ambulance = {chosen_ambulance}\")                \n",
    "                if counter == chosen_ambulance:\n",
    "\n",
    "                  ambulance.position = movement\n",
    "                  a_rq = env_q_learning.n - 1\n",
    "                  #print(f\"sí entró {ambulance.position}\")\n",
    "                \n",
    "                counter += 1 \n",
    "              else:\n",
    "                a_rq = -1                \n",
    "\n",
    "              #print((str(state_q), str(next_state_q)))\n",
    "              ambulance.g_q += a_rq\n",
    "              options = ambulance.q_qlearning_(str(next_state_q))\n",
    "              current = ambulance.q_qlearning_(str(state_q))[ambulance.a_q]\n",
    "              # Q-learning updates, note the second argument\n",
    "              ambulance.q_qlearning[str(ambulance.seen_state)][ambulance.a_q] = ambulance.q_learning(current, options, a_rq)\n",
    "              #print(ambulance.q_qlearning)\n",
    "              #print(q_qlearning)\n",
    "              state_q = next_state_q\n",
    "\n",
    "   \n",
    "        rewards_qlearning_cp[i] += g_q_cp     \n",
    "\n",
    "        for ambulance in env_q_learning.ambulances:\n",
    "          ambulance.rewards_qlearning[i] += ambulance.g_q\n",
    "          ambulance.g_q = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oii_yg14QoyW",
    "outputId": "d41c3a52-afd3-43ee-959a-e1bacf9f9673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-431., -432., -450., -465., -490., -460., -440., -429., -449.,\n",
       "       -480., -467., -459., -446., -466., -455., -418., -427., -419.,\n",
       "       -399., -406., -433., -414., -442., -427., -435., -397., -433.,\n",
       "       -442., -426., -396., -416., -420., -437., -451., -406., -425.,\n",
       "       -395., -453., -412., -414., -462., -409., -426., -450., -433.,\n",
       "       -412., -435., -428., -397., -434., -415., -421., -399., -414.,\n",
       "       -450., -429., -405., -413., -403., -409., -414., -403., -443.,\n",
       "       -438., -409., -421., -455., -427., -427., -405., -415., -427.,\n",
       "       -435., -403., -390., -421., -434., -438., -392., -409., -439.,\n",
       "       -395., -425., -415., -434., -437., -464., -399., -430., -396.,\n",
       "       -369., -359., -425., -430., -423., -375., -458., -396., -414.,\n",
       "       -434.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_qlearning_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFxGdE72Q8Op",
    "outputId": "5db5a6ae-50d9-4e12-f424-0954617eaa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-298. -276. -298. -326. -302. -284. -256. -236. -284. -346. -326. -328.\n",
      " -262. -298. -312. -222. -256. -290. -228. -230. -288. -318. -292. -246.\n",
      " -244. -218. -230. -300. -296. -230. -252. -276. -314. -288. -284. -296.\n",
      " -252. -320. -256. -270. -288. -224. -278. -318. -260. -240. -326. -312.\n",
      " -314. -312. -288. -282. -232. -248. -258. -272. -234. -274. -222. -224.\n",
      " -202. -248. -296. -298. -226. -258. -332. -264. -258. -290. -300. -270.\n",
      " -340. -254. -304. -306. -252. -348. -272. -292. -326. -254. -280. -274.\n",
      " -338. -292. -330. -212. -302. -234. -220. -162. -256. -260. -264. -200.\n",
      " -338. -236. -218. -306.]\n",
      "[-262. -282. -326. -350. -388. -322. -276. -298. -300. -330. -292. -282.\n",
      " -290. -336. -280. -266. -292. -266. -280. -260. -288. -196. -304. -276.\n",
      " -300. -242. -300. -290. -262. -240. -254. -230. -260. -302. -256. -280.\n",
      " -210. -284. -214. -254. -334. -242. -244. -272. -254. -282. -260. -246.\n",
      " -212. -264. -268. -250. -224. -270. -318. -266. -252. -252. -254. -288.\n",
      " -268. -228. -292. -218. -272. -242. -278. -258. -272. -226. -216. -288.\n",
      " -254. -256. -214. -224. -292. -236. -216. -244. -264. -224. -234. -248.\n",
      " -266. -274. -354. -248. -236. -256. -180. -192. -272. -294. -276. -210.\n",
      " -296. -238. -278. -246.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(env_q_learning.n):\n",
    "  print(env_q_learning.ambulances[i].rewards_qlearning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzhbviZrSDZE",
    "outputId": "ca9c5b4c-6afd-4550-d270-29399342258b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambulance 1\n",
      "{'[0, 0, 0, 2]': [-1.1013836239655974, 0.10958737000000002, 0],\n",
      " '[0, 0, 1, 1]': [-1.036847437585972, 0.16979884532904724, -0.9480007463790864],\n",
      " '[0, 0, 2, 0]': [-0.8563936266878179, -0.1923398517109, -0.854953427258105],\n",
      " '[0, 1, 0, 1]': [-1.0291846847274915,\n",
      "                  0.10651000000000001,\n",
      "                  -0.8295527033091146],\n",
      " '[0, 1, 1, 0]': [-1.0271803266070751,\n",
      "                  0.007000000000000006,\n",
      "                  -0.7201668523701025],\n",
      " '[0, 2, 0, 0]': [-0.8295636003505017,\n",
      "                  0.09520222900000001,\n",
      "                  -0.6324162746101619],\n",
      " '[1, 0, 0, 1]': [-1.0230929168574883, -0.27949, -0.5539401671330922],\n",
      " '[1, 0, 1, 0]': [-1.0187490639463679, -0.1599257, -0.6722646471491457],\n",
      " '[1, 1, 0, 0]': [-0.9002850873653906, -0.1, -0.49786861968038276],\n",
      " '[2, 0, 0, 0]': [-0.8892056526282117, 0, -0.4775593471491457]}\n",
      "Ambulance 2\n",
      "{'[0, 0, 0, 2]': [-0.7612403165401, -0.4950503249086621, 0],\n",
      " '[0, 0, 1, 1]': [-0.798150180266563, -0.2662298766557546, -0.7046003872767842],\n",
      " '[0, 0, 2, 0]': [-0.7382909456092078,\n",
      "                  -0.19632631570958686,\n",
      "                  -0.770720973062082],\n",
      " '[0, 1, 0, 1]': [-0.9998341616116263, -0.10894668277, -0.7452455256245355],\n",
      " '[0, 1, 1, 0]': [-0.538954682084812, -0.19297361497, -0.779105673062082],\n",
      " '[0, 2, 0, 0]': [-0.8063067682083491,\n",
      "                  -0.35990287958755307,\n",
      "                  -0.8061369386464874],\n",
      " '[1, 0, 0, 1]': [-0.9992129995361332,\n",
      "                  -0.09912049900000001,\n",
      "                  -0.8069843142049739],\n",
      " '[1, 0, 1, 0]': [-0.9427216554735631,\n",
      "                  -0.27946546192210003,\n",
      "                  -0.6363203311694652],\n",
      " '[1, 1, 0, 0]': [-0.9976324665116179,\n",
      "                  -0.15990287958755303,\n",
      "                  -0.8285232447818387],\n",
      " '[2, 0, 0, 0]': [-0.9972318533206537, 0, -0.8287916452649386]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "for i in range(env_q_learning.n):\n",
    "  print(f\"Ambulance {i+1}\")\n",
    "  pprint.pprint(env_q_learning.ambulances[i].q_qlearning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "BkJ_1LW7v-a5",
    "outputId": "278d8184-1035-4554-b1d8-498eec9a9ee2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_rewards(plots):\n",
    "    plt.figure()\n",
    "    for plot in plots:\n",
    "      method, method_title = plot\n",
    "      plt.plot(method, label=method_title)\n",
    "      # plt.plot(r_qlearning, label='Q-learning')\n",
    "      plt.xlabel('Episodes')\n",
    "      plt.ylabel('Sum of rewards during episodes')\n",
    "      plt.ylim([-200, 0])\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(plot_rewards( [[rewards_qlearning_cp/runs, 'Q-learning']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "Ns4R9x0zG4wC",
    "outputId": "eb1aa68d-57ce-4065-cac4-acfb804a70d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(plot_rewards( [(env_q_learning.ambulances[i].rewards_qlearning/runs, f\"ambulance {i}\") for i in range(env_q_learning.n)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA7dwa4Rwfxi"
   },
   "source": [
    "## Observations and Conclusions\n",
    "\n",
    "The results in the experiment of n=2, m=4 and p = (.2 , .6 ,. 2 ,0 ) are quite surprising. Even though there are more agents in the system, the amount of patients that are unattended is approximately the same as the average best solution of the achieved learning result in the first setting. \n",
    "\n",
    "Moreover, the ambulances do not learn a better way to minimise their expected waiting time. This could be caused by the lack of convergence in the estimation of the state-action function. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y_KVtpxhc9s"
   },
   "source": [
    "# Information Design: Central Planner Sends Recommendations to Ambulances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTs0vAzKhn2c"
   },
   "source": [
    "This section proposes a solution for the ambulance problem inspired by the seminal work of Kamenicka and Gentskow in 2011 and the recent implementation as a Markov Persuasive Model by Wu in 2022.[6][12]\n",
    "\n",
    "In this model we have the same setting as before, but now the central planner and independent ambulances coexist in the same environment. The former tries to minimise lost patients, while the latter-the expected waiting time between patients. The central planner cannot work as a dictator because ambulances are not directly dependent on him, but the central planner has more information than ambulances about the arrival of patients in the city, and it can use that information to his advantage to persuade the ambulances into taking particular actions. Recall that ambulances only know their private information about the rate of patients, based solely on their own experience.\n",
    "As a consequence, the central planner needs to design a persuasion signalling message for each ambulance privately, subject to ensuring that the ambulances will be obedient.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ikJ0t7J9gPD"
   },
   "source": [
    "## Information Design Preliminaries\n",
    "\n",
    "Information design focuses on two agents: a sender with a utility function $v$, and a receiver with utility function $u$. Both utility functions depend on $\\omega$, which is the realised outcome of certain environment uncertainty, and $a$, which are the actions of the receivers. The main concept behind the persuasion problem is how does the sender reveal information about $\\omega$ s.t. the expectation of the utility function $v$ is maximised.\n",
    "The sender follows a signalling scheme which is the conditional distribution of the signal, random variable, given the outcome of $\\omega$. Once the outcome $\\omega$ is available, the sender samples a signal and sends it to the receiver, which in turn chooses an action,$a$, based on Bayes’ theorem s.t. her expected utility function,$u$, is maximised. The optimal signalling schemes are often direct and persuasive: direct signal schemes imply that each signal will induce a recommended action for the receiver, while persuasive signal schemes imply that the recommended action maximises $u$. Persuasiveness is defined as:\n",
    "$$Pers(\\mu,\\{V(s)^i\\}_{i=1}^n) = \\{\\pi_t: S \\rightarrow\n",
    "P^n : \\sum_{\\omega \\in \\Omega} \\mu (\\omega)\\pi(a|s,\\omega)[Q^i(s,a)-Q^i(s,a')], \\ \\forall i \\in [n],a,a' \\in A^i, s \\in S \\}\n",
    "$$\n",
    "where the π term indicates the probability of action a being recommended given that $\\omega$ outcome has occurred, while the 𝞵 term indicates the priori from which the environment uncertainty is drawn.[12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCHCBc1zkz4P"
   },
   "source": [
    "## Markov Persuasive Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpm1FK7pldyf"
   },
   "source": [
    "Markov Persuasion Processes (MPPs) introduce the idea of information\n",
    "processors and decision makers. The sender’s aim is to influence the myopic receivers in such a way that their actions maximise the sender’s cumulative utilities, in this case rewards. MPPs assume a finite horizon Markovian environment with varying prior and utility functions which is indeed the case in the ambulance problem. MPPs find the optimal policy,given that the state space is finite, by adding persuasion to the Bellman equation.\n",
    "\n",
    "\n",
    "\n",
    "## The Model\n",
    "\n",
    "Ambulances have the same action space: Left, Right, or Stay. \n",
    "\n",
    "The central planner has two types of information: state and outcome. The first one is as before, while the second one is the knowledge about rate of arrival of patients in each region. The outcome has a prior distribution. \n",
    "The central planner use this outcome information to create the signals to ambulances about where to position themselves. \n",
    "\n",
    "As before the state changes due to the ambulance's actions. The payments of both the ambulances and the Central planner depend on the joint action of all ambulances. The probability transition is affected by the state, action, and the revealed information $\\omega_h$ which is the place where the patient appeared $P_t(s_{t+1}|s_t,\\omega_t,a_t)$. \n",
    "The central planner has a prior of what $\\omega_h$ is going to be, and it is the only one that always sees the realised $\\omega_h$, while the only time an ambulance sees a realisation is when it attends a patient. \n",
    "\n",
    "The MPP goes as follows.\n",
    "1. There are ambulances and each doesn't know any prior distribution about the arriving rate of patients, just what they have learnt through their own experience. Their reward is as before: $-(n-1)$ if they don't attent a patient in the step $t$, and 0 otherwise.\n",
    "\n",
    "2. The sender can see the valuation of each ambulance and it commits to a persuasive signal $\\pi_t: S \\rightarrow\n",
    "P^n$ where $P$ is a mapping from $\\Omega \\rightarrow △(A)$ - a probability distribution of where a patient will be, for each ambulance.\n",
    "\n",
    "3. The central planner receives the call for the patient in a region (realized $\\omega_t$). Subsequently,it recommends to the receiver to take an action $a_t \\sim \\pi_t(.|s_t, \\omega_t )$. \n",
    "\n",
    "4. Given the recommendation of the action $a^i_t$, all ambulances take an action $a'^{i}_t$ and get a reward. \n",
    "\n",
    "5. The ambulance that got the patient is moved to another region and so a new state $s_{t+1}$ is realised.\n",
    "\n",
    "We restrict the policy of the central planner to be persuasive.\n",
    "\n",
    "$$Pers(\\mu,\\{V(s)^i\\}_{i=1}^n) = \\{\\pi_t: S \\rightarrow\n",
    "P^n : \\sum_{\\omega \\in \\Omega} \\mu (\\omega)\\pi(a|s,\\omega)[Q^i(s,a)-Q^i(s,a')], \\ \\forall i \\in [n],a,a' \\in A^i, s \\in S \\}\n",
    "$$\n",
    "## Optimal Ambulances Problem\n",
    "\n",
    "It is the same as the one in setting 2. They want to minimise the expected discounted reward in a finite horizon, namely:\n",
    "$$V^{\\pi,i} (s) = E[\\sum_{t=1}^T \\gamma^{i-1} R^i_t|S_t = s]$$\n",
    "\n",
    "Similarly to setting 2, ambulances are independent learners and take the moment given. \n",
    "\n",
    "The Q-function for the ambulance is as before $Q^{Pi}_t: S \\times A \\rightarrow \\mathbb{R}$ \n",
    "\n",
    "## Optimal Signal Policy Problem in MPPs\n",
    "\n",
    "The value function of the central planner is as before, but it also takes $P$ and $\\mu$ into consideration:\n",
    "\n",
    "$$V^{\\pi}_{P,\\mu} (s) = E[\\sum_{t=1}^T  \\gamma^{i-1} R^i_t|S_t = s]$$\n",
    "\n",
    "The reward is -1 if the patient wasn't attended and 0 otherwise.\n",
    "\n",
    "We define the Q-function as $Q^{Pi}_t: S \\times \\Omega \\times A \\rightarrow \\mathbb{R}$\n",
    "\n",
    "For any Q-function:\n",
    "$$⟨Q_t, \\mu_t \\otimes \\pi_t ⟩_{\\Omega \\times A} = E_{ \\omega  \\sim  μ_t, a \\sim \\pi_t(.|s,\\omega)} [Q_t(s, \\omega, a]$$\n",
    "\n",
    "The bellman optimality equation is:\n",
    "\n",
    "$$V^*_t(s) = max_{\\pi'_t \\in Pers(\\mu,\\{V(s)^i\\})} ⟨Q^*_t, \\mu_t \\otimes \\pi_t ⟩_{\\Omega \\times A}$$\n",
    "\n",
    "[12]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrW57guxv_2l"
   },
   "source": [
    "## Reinforcement Learning Problem\n",
    "\n",
    "In real life prior about the state of the world or the distribution of arrival of agents per region is unkown to the central planner. Additionally, the transtion of state to state, given by the movement of ambulances after they attended a patient is unkown. This uncertainty suggests the use of a Reinforcement Learning approach to the sequential decision optimisation of the central planner described above.\n",
    "\n",
    "To solve this problem, the paper from Wu et al.  tackles the lack of knowledge of utility functions, prior distributions, and the Markov transition kernels, by introducing the Optimism-Pessimism Principle for Persuasion Process. The OP4 algorithm introduces a novel combination of pessimism and optimism in addition to the general optimal policy. Exploration is encouraged through the optimism terms, while the signalling policy of the sender is robustified through pessimism terms in order to prevent the decision makers’ harmful equilibrium behaviour.\n",
    "\n",
    "**Pessimism**\n",
    "\n",
    "Given the set of data, the true value of 𝞵t is not obtainable. Instead, before each episode, we construct a confidence region that contains the true priore with a high probability. Afterwards, we find the signalling policies that are persuasive towards all distributions in the confidence interval. Given that the confidence region is accurate, the signalling policy is persuasive in terms of the true prior with certainty. The aim of pessimism is to prompt robust equilibrium dynamics.\n",
    "\n",
    "**Optimism**\n",
    "\n",
    "The uncertainty of the Q-function is a reflection of the uncertainty about the underlying model. The addition of the uncertainty recommends actions with high uncertainty, which in turn results in the receiver taking the particular action, given that the condition of persuasiveness is satisfied. The aim of optimism is to motivate exploration alongside exploitation.\n",
    "The principles of pessimism and optimism are further intertwined in the OP4 algorithm as follows:\n",
    "\n",
    "- **for** episode *t*=1...*T* **do**\n",
    "\n",
    "  > Receive the initial state {$s_1$} at time *t*\n",
    "\n",
    "  > for each step $h \\in H$ \n",
    "  estimate prior $\\mu_h^t$ along the confidence interval $\\mu_B$, and construct an optimistic *Q*-function $Q_h^t$ iteratively with the value function $V_h^t$\n",
    "\n",
    "  > **for** step *h*=1,...*H* **do**\n",
    "  >> Choose robust signaling sceheme $\\pi_h^t \\in argmax_{\\pi_h \\in Pers(\\mu_B,u_h)} ⟨Q^*_t, \\mu_t \\otimes \\pi_t ⟩_{\\Omega \\times A}(s_h^t;C^t)$\n",
    "\n",
    "  >> Observe state $s_h$, outcome $\\omega_h$ and accordingly recommend action $a$~$\\pi_h^t(\\omega_h,.)$ to the receiver.\n",
    "\n",
    "  > **end for** \n",
    "\n",
    "  **end for**\n",
    "\n",
    "One of the main challenges is the tradeoff between uncertainty and revelation of the full information for both the environment and receivers. In the case of uncertainty, the optimal policy might not lead to the desired actions of the decision makers due to lack of persuasiveness, while in the complete information environment, decision makers' actions tend to converge to a suboptimal cumulative reward for the sender, in our case the central planner.[12]\n",
    "\n",
    "**Challenges of the Reinforcement Learning Problem in our model**\n",
    "\n",
    "Compared to Wu et al. paper, our model has independent ambulances that don't disappear when they take an action, but keep learning through all the episode. This is an extra complication and it is not assured that OP4 could work. The particular questions to attend are the following:\n",
    "- How to establish an algorithm that addresses the problem of learning the outcome distribution to design the signal policies while taking into consideration that the receivers (ambulances) would be learning what the central planner suggests via signals?\n",
    "- Does this algorithm achieve a stable solution at each iteration after being trained?\n",
    "- Is there a suboptimal outcome of the algorithm when you introduce learning agent that lives through all the episode versus the ones that disappear as defined by Wu et al.?\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I0ywNNGiycl"
   },
   "source": [
    "# Ehtical Implications/Further Applicable Suggestions\n",
    "Considering the fact that human lives are at stake, it will be expected that the nature of the algorithm is shared at least with the people in charge of the state. Given that the algorithm implies that not all information available is shared at all times, this can lead to significant moral and ethical discussions and might even be scraped off despite potentially decreasing the death rate amongst cases where ambulances are involved. However, we believe that if the algorithm achieves better performance than the status quo, ethical dilemmas will be overcome. \n",
    "\n",
    "In real life, the ambulance response time often depends on the severity of each case. Thus, it will make sense to implement a severity metric that would suggest which patient should be attended first, considering the fact that at each time step in real life applications more than one patient would appear. This would further increase the complexity of the algorithm, but it may significantly improve the performance with regards to the most important metric: human lives. This suggestion is based on John Rawls' maximin criterion with regards to fairness and justice. The 20th century philosopher suggests that a just system will maximise the position of the least fortunate people, in our case patients in the emergency health system.[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Further Applications\n",
    "**Urban Planning**:\n",
    "Considering the increasing size and density of megacities, the idea of creating a system of independent and self-sufficient regions/neighbourhoods seems like an optimal solution towards the problem of overpopulation and inequality between living conditions of individuals. We propose implementing the MPP model, defining an urban planner as the sender, and a set of real estate companies/developers as the receivers. The idea is to optimise the land available for future projects in such a way that each region is self-sufficient. We define the utility function of the urban planner as the sum of ‘self-sufficiency’ coefficients of all regions within the city that can be determined by various parameters such as the number of shops,residential buildings, hospital etc. per area/residents. The utility functions of each real estate developer is defined as their expected profit from undertaking a project, based on expected prices and sale rate. Each parcel of land is dedicated to a particular set of buildings,e.g. residential, thus enabling the sender to send various signals to different real estate developers based on their interests/specialisation. This will induce the application of auction theory as well since we assume that a set of companies will be informed of an available parcel. This will also maximise income for the state as the conflict between companies will theoretically lead to higher prices. One way to induce persuasiveness is to set an upper bound of the informed developers per parcel. In addition, the sent signal should avoid informing the same set of companies for multiple parcels. For example, we would rather have company A against companies B and C for one parcel, and company A against companies E and D for another. Thus, we aim to avoid overlapping companies in more than 1 auction. This limits the set of possibilities for signalling policies, but tackles the problem of cooperation between companies: e.g. if two companies were aiming for a parcel each and they were allocated in two different auctions, they could use their resources with weights w1=(1,0) and w2=(0,1) respectively in order to maximise the probability of obtaining a single parcel.  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckE6nzBfxAQX"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The report focuses on the implementation of Reinforcement Learning algorithms, aiming at the improvement of ambulance allocation within a city and respectively decreasing the number of human lives lost. The first two settings produce similar results, that don't conclude which of the two systems would produce better results in real life. The third setting will potentially produce the best performance, but its complexity shouldn't be undermined especially when it comes to such a dynamic and complex environment as the emergency system in Mexico City. The MPP model could present some ethical issues, but its implementation would ensure that response time is optimised and decreases the chance of mistakes,often made by human interactions and decisions. Thus,we believe that Reinforcement Learning implementation in ambulance allocation will produce the best results for society in general:decreasing the number of human lives lost. \n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJZRb4dLvWaH"
   },
   "source": [
    "# References\n",
    "- [1] Aristi Reina, Francisco. “Regla De Asignación Eficiente De Ambulancias En Un Entorno Dinámico.” ITAM, 2019. \n",
    "\n",
    "- [2] Bowling, Michael, and Manuela Veloso. “Rational and Convergent Learning in Stochastic Games.” IJCAI’01, vol. 2, Aug. 2001, https://doi.org/1642194.1642231. \n",
    "\n",
    "- [3] Daskalakis, Constantinos, et al. “The Complexity of Markov Equilibrium in Stochastic Games.” ArXiv, 8 Apr. 2022, https://doi.org/arxiv:2204.03991v1. \n",
    "\n",
    "- [4] Foerester, Jakob, et al. “Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning.” International Conference of Machine Learning, 2017, pp. 1146–1155., https://doi.org/10.48550/arXiv.1702.08887. \n",
    "\n",
    "- [5] Jackson, Matthew O. “Mechanism Theory.” SSRN Electronic Jour-\n",
    "nal, 2014, doi:10.2139/ssrn.2542983.\n",
    "\n",
    "- [6] Kamenica, Emir, and Mathew Gentzkow. “Bayesian Persuasion.” American Economic Review, vol. 101, no. 6, Oct. 2011, pp. 2590–2615., https://doi.org/10.1257/aer.101.6.2590. \n",
    "\n",
    "- [7] Matignon, Laetitia, et al. “Independent Reinforcement Learners in Cooperative Markov Games: a Survey Regarding Coordination Problems.” The Knowledge Engineering Review, vol. 27, no. 1, 2012, pp. 1–31., doi:10.1017/S0269888912000057.\n",
    "\n",
    "- [8] Mguni, David, et al. “ Coordinating the Crowd: Inducing Desirable\n",
    "Equilibria in Non-Cooperative Systems.” Prowler, 30 Jan. 2019,\n",
    "doi:arXiv:1901.10923\n",
    "\n",
    "- [9] Pecorino, Philip. \"Rawls and The Maxi Min Principle.\" Queensborough Community College,  CUNY: Computers, Information Technology, the Internet, Ethics, Society and Human Values. June 2006.\n",
    "\n",
    "- [10] Propuesta para hacer más eficiente la atención de Urgencias Médicas en la CDMX. Investigación del C5. Agosto 2019.\n",
    "\n",
    "- [11] Tan, Ming. “Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents.” International Conference on Machine Learning, 1993, pp. 330–337. \n",
    "\n",
    "- [12] Wu, Jibang, et al. “Sequential Information Design: Markov Persuasion Process and Its Efficient Reinforcement Learning.” ArXiv, 22 Feb. 2022, https://doi.org/10.48550. \n",
    "\n",
    "- [13] Zhang, Kaiqing, et al. “Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms.” Corr, abs/1911.10635, 28 Apr. 2021, https://doi.org/arxiv:1911.10635v2. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#️Contribution \n",
    "Both team members have contributed equally.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ambulance Allocation Reinforcement Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
